%!TEX root = ../DDE-Project-Master.tex

\section{Preliminaries}

\subsection{DDEs covered by the proposed approach} We consider systems of nonlinear DDEs involving multiple discrete or distributed delays, either in the linear term or in the nonlinearity. Such DDEs can be put into the following form: 
\bea \label{Eq_DDE_general}
\frac{\d \boldsymbol{x}(t)}{\d t}  = \boldsymbol{A} \boldsymbol{x}(t) & + \sum_{i=1}^p \boldsymbol{B}_i  \boldsymbol{x}(t-\tau_i) + \sum_{i=1}^p \boldsymbol{C}_i  \int^t_{t-\tau_i} \boldsymbol{x}(s) \d s \\
& +  \boldsymbol{F} \left(t, \boldsymbol{x}(t), \boldsymbol{x}(t-\tau_1), \cdots, \boldsymbol{x}(t-\tau_p), \int^t_{t-\tau_1} \boldsymbol{x}(s) \d s, \cdots, \int^t_{t-\tau_p} \boldsymbol{x}(s) \d s\right),
\eea
where the unknown function $\boldsymbol{x}$ is a $d$-dimensional vector; $p$ is a positive integer, representing the total number of delays; the $\tau_i$'s are distinctive positive scalars arranged in ascending order; $\boldsymbol{A}$, $\boldsymbol{B}_i$, and $\boldsymbol{C}_i$ ($1\le i \le p$) are given $d\times d$ matrices; and $\boldsymbol{F}\colon \mathbb{R}^{2+2p} \rightarrow \mathbb{R}^d$ is a given continuous vector function.

In order to simplify the presentation, we first articulate our main contribution in a simple setting of a scalar DDE with a single discrete delay $\tau>0$:
%\bea\label{eq:dde}
%    \frac{\d x(t)}{\d t} &= ax(t) + bx(t-\tau) + F(x(t-\tau)), & t&> 0 \\
%    x(t) &= \varphi(t), & t&\in[-\tau, 0],
%\eea
\be\label{eq:dde}
    \frac{\d x(t)}{\d t} = ax(t) + bx(t-\tau) + F(x(t-\tau)), 
\ee
where \(a,b\in\R\), and \(F:\R \to \R\) is a given scalar function. Results for the general case of \eqref{Eq_DDE_general} is provided afterward in Section~\ref{Sect_convergence_system_case}. 


{\alert************************************
\bi
\item Explain in a short paragraph the main difficult compared with the case dealt with in \cite{CGLW16}.
\item To cope with the difficulties, we restrict the initial data to $C^2$ functions. Refer to Section~\ref{Sect_convergence_system_case} for results about existence and regularity. 
\ei

************************************
}

\subsection{The Abstract Formulation of the Linear Operator}

It is appropriate to reformulate \cref{eq:dde} into an abstract ordinary differential equation on the Hilbert space 
\be
    \mcH := L^2([-\tau, 0);\R) \times \R,
\ee
where the inner product is defined for \((f_1, \gamma_1),\, (f_2, \gamma_2) \in \mcH \), as:
\be \label{H_inner}
    \langle (f_1, \gamma_1), (f_2, \gamma_2) \rangle_{\mathcal{H}} := \frac1 \tau \int_{-\tau}^0 f_1(\theta)f_2(\theta)  \d \theta  + \gamma_1\gamma_2.
\ee
However, it is not yet possible to represent \(F\) in this space, so we focus on the linear part of \cref{eq:dde}. Define the linear operator \(\mcA: D(\mcA) \to \mcH\) by
\bea \label{def:mcA}
    \lbrack \mcA \Psi \rbrack (\theta) & := \begin{cases}
    {\displaystyle \frac{\d^+ \Psi^D}{\d \theta}}, &  \theta \in[-\tau, 0),  \vspace{0.5em}\\ 
    {\displaystyle a\Psi^S + b\Psi^D(-\tau)}, & \theta = 0,
    \end{cases}   
\eea
for any \(\Psi = (\Psi^D, \Psi^S)\) that lives  in the domain,  \(D(\mathcal{A})\), defined as
\be \label{D_of_A2}
    D(\mcA): = \left\{\Psi \in \mcH : \Psi^D \in H^1([-\tau, 0); \mathbb{R}^d), \lim_{\theta \to 0^-} \Psi^D(\theta) =\Psi^S \right\}.
\ee
It is clear that if \(x:[-\tau,\infty)\) satisfies the linear DDE
\bea\label{eq:linear_dde}
    &\frac{\d x(t)}{\d t} = ax(t) + bx(t-\tau), & t &> 0 \\
    &x(0) = \alpha, && \\
    &x(t) = f(t), & t&\in[-\tau, 0)
\eea
then \(u(t) = (x_t, x_t(0))\), where \(x_t(\theta)= x(t+\theta)\) for \(\theta\in[-\tau,0)\), satisfies the linear, abstract ODE
\bea\label{eq:linear_abstract_ode}
    &\frac{\d u}{\d t} = \mcA u, &  t>0 \\
    &u(0) = u_0, &
\eea
where \(u_0 = (f, \alpha).\) From \cite[Thm.~2.4.1]{CZ95}, the DDE in \cref{eq:linear_dde} has a solution \(x(t)\). Furthermore, if we define \(T(t):\mcH\to\mcH\) by
\be\label{semigroup}
T(t)( f, \alpha) := (x_t, x_t(0)), \quad t\geq0,
\ee
then \(T(t)\) is a \(C_0\)-semigroup on \(\mcH\) and \(\mcA\) is its infinitesimal generator \cite[Thm.~2.4.4; Thm.~2.4.6]{CZ95}. With this, we know that the solution to \cref{eq:linear_abstract_ode} is \(T(t)u_0.\)

\subsection{The Space \(X\)}

In order for us to make sense of the nonlinear part of \cref{eq:dde}, we look at a certain subset of the space \(\mcH\). We define the following inner product space with elements in 
\be
    X := \mathcal C^+([-\tau, 0) ; \mathbb R) \times \mathbb R \subseteq \mcH,
\ee
where \(\mathcal C^+([-\tau, 0))\) denotes the set of bounded right-continuous functions on the interval \([-\tau, 0)\), and the inner product defined by
\be
    (\Phi, \Psi)_X := \Phi^S\Psi^S + \frac 1 \tau (\Phi^D, \Psi^D)_{L^2([-\tau, 0))} + \Phi^D(-\tau)\Psi^D(-\tau), \quad \Phi,\Psi\in X.
\ee
Note that this is defined since if \(f\in C^+([-\tau, 0)\) then \(f\in L^2([-\tau,0)\). It is relatively straight-forward to verify that \((\cdot, \cdot)_X\) is symmetric, bilinear, and positive definite and thus an inner product. We will also make use of the norm \(\|\cdot\|_X\) induced from this inner product. Note that \(X\) is \textbf{not} a Banach space since Cauchy sequences might not converge in \(X\). 

We can then define \(\mcF:X\to X\subseteq\mcH\) by 
\bea \label{mcF}
    [\mcF (\Psi) ](\theta) & := \begin{cases}
    0, &  \theta \in[-\tau, 0),   \vspace{0.4em}\\ 
    F \left( \Psi^D(-\tau) \right), & \theta = 0, 
    \end{cases}  \quad {\Forall \Psi = (\Psi^D, \Psi^S) \in  X}.
\eea
From \cite[Thm.~2.4.1]{CZ95}, if \(u_0\in X\), then the solution \(x(t)\) of \cref{eq:dde} with initial conditions \(x_0 =  u_0^D\) and \(x(0) = u_0^S\) is continuous on \([0,\infty)\). Therefore, \(x_t\) is in \(\mathcal C^+([-\tau, 0))\) and \(u(t)\in X\) for any \(t\in[0,\infty)\). Now if we set \(u(t) = (x_t, x_t(0))\) where \(x\) is the solution to \cref{eq:dde}, then \(u\) satisfies the following abstract ODE:
\bea\label{eq:abstract_ode}
    \frac{\d u}{\d t} &= \mcA u(t) + \mcF(u(t)), \\
    u(0) &= u_0.
\eea
From the above, we can derive the variation of constants formula:
\be
    u(t) = T(t)u_0 + \int_0^t T(t-s)\mathcal F(u(s)) \d s.
\ee
For a derivation c.f. \cite[pg.~105]{P83}.

\subsection{Properties and Basic Results of Koornwinder Polynomials}


From \cite[Eq.~(2.1)]{Koornwinder}, the sequence of Koornwinder polynomials \(\{K_n\}\) can be built from the Legendre polynomials \(L_n\) by 
\be\label{eq:Pn}
    K_n(s) := -(1+s)\frac d {\d s} L_n(s)+ (n^2+n+1)L_n(s), \quad s\in[-1,1],\  n\in\Nzero.
\ee

Furthermore, we reproduce from \cite[Prop.~3.1]{CGLW16} some simple properties that \(\{K_n\}\) satisfy.
\bprop\label{prop:koorn_properties}
The polynomial \(K_n\) defined in \eqref{eq:Pn} is of degree \(n\) and  admits the following expansion in terms of the Legendre polynomials:
\be\label{eq:Pn2}
    K_n(s) = - \sum_{j = 0}^{n-1} (2j+1)L_j(s) + (n^2 + 1) L_n(s), \qquad n \in \Nzero;
\ee
and the following normalization property holds:
\be
    K_n(1) = 1, \qquad n \in \Nzero.
\ee

Moreover, the sequence given by
\be
    \{\mathcal{K}_n := (K_n, K_n(1)) : n \in \Nzero\}
\ee 
forms an orthogonal basis of the  product space 
\be
    \mathcal{E} := L^2([-1,1); \R) \times  \R,
\ee 
where \(\mcE\) is endowed with the following inner product:
\be
    \langle (f, a), (g, b) \rangle_\mcE = \frac 1 2 \int_{-1}^1 f(s)g(s) \d s  + ab, \quad (f,a), (g, b) \in \mcE.
\ee

Finally, \(\left\{ \frac{\mcK_n}{\| \mcK_n \|_\mcE} \right\}\) forms a Hilbert basis of $\mcE$ where 
the norm \(\| \mcK_n \|_\mcE\) of \(\mcK_n\) induced by  \(\langle \cdot, \cdot \rangle_\mcE\)  possesses the following analytic expression:
\be \label{eq:Pn_norm}
    \|\mcK_n\|_\mcE = \sqrt{\frac{(n^2+1)((n+1)^2+1)}{2n+1}}, \qquad n \in \Nzero.
\ee
\eprop

Suppose that \(\Pi^\mcE_N\) is the \(N\)-dimensional standard projection into \(\mbox{span}\{\mcK_n: n\leq N\} \subset \mcE\). It will be relevant to discuss when we have convergence of \([\Pi^\mcE_N u]^D\) for \(u\in\mcE\). In particular, we will focus on uniform convergence. 

\bprop\label{prop:uniform-conv}
Let \(f\in \mathcal C^2([-1,1];\mathbb R)\) and denote \(\psi = (f, f(0)) \in\mcE\). Then the series
\be\label{koorn-series}
    [\Pi^\mcE_N\psi]^D = \sum_{n=0}^N \frac{\langle \psi, \mcK_n \rangle_\mcE}{\| \mcK_n \|^2_\mcE} K_n
\ee
converges uniformly to \(f\).
\eprop
See Appendix~\ref{Appendix_proofs} for a proof.

It will also be necessary to prove certain properties of the series of Koornwinder polynomials
\be\label{eq:SN}
    S_N(x) := \sum_{n=0}^N \frac{K_n}{\| \mcK_n \|_\mcE^2}, \quad N\in\Nzero,\  x\in[-1,1].
\ee
If we were to denote \(\psi = (0,1) \in L^2([-1,1)) \times \R\), then \(S_N\) would simply be the functional part of \(\Pi_N\psi\). The following lemma allows us to express \(S_N\) in terms of Legendre Polynomials. Now that we have this expression, we can prove the properties of \(S_N\) that will be useful when showing the main result.

\bl \label{lemma:S_N}
The functions \(S_N\) defined in \eqref{eq:SN} can be expressed as
\be\label{eq:SN_Legendre}
S_N(x) = \frac 1 {(N + 1)^2 +1} \sum_{n=0}^N (2n + 1) L_n, \quad x\in[-1,1].
\ee

Moreover,
\be\label{eq:uniform-bdd}
    |S_N(x)| < 1, \quad \forall N\in\Nzero,\ \forall x\in[-1,1],
\ee
and
\be\label{eq:pw-conv}
    \lim_{N\to\infty} S_N(x) = 0, \quad \forall x\in(-1,1).
\ee
\el
See Appendix~\ref{Appendix_proofs} for a proof.

\br
It can easily be shown that \(\lim_{N\to\infty}S_N(-1) = 0\) and \(\lim_{N\to\infty} S_N(1) = 1\), which both follow from the expression \cref{eq:SN_Legendre} when evaluated at \(\pm1\).  However, for our main results we need only that \(S_N \to 0\) almost everywhere on \([-1,1]\). Therefore we omit the proof of this.
\er

Applying a linear transformation to the orthogonal polynomials on \([-1,1]\) will give us a set of orthogonal polynomials on \([-\tau,0]\), from which we can construct an orthogonal basis on \(\mcH\). We define a linear transformation \(\mathcal T\) by
\be \label{eq:linear_transf}
    \mathcal{T} \colon [-\tau, 0] \rightarrow [-1, 1], \qquad \theta \mapsto 1 + \frac{2 \theta }{\tau}. 
\ee
We can now define the polynomial \(K^\tau_n\) by 
\bea \label{eq:Pn_tilde}
    K^\tau_n\colon  [-\tau, 0] & \rightarrow \mathbb{R}, \\
    \theta & \mapsto  K_n \Bigl( 1 + \frac{2 \theta }{\tau} \Bigr), \qquad n \in \mathbb{N}.
\eea
Since the sequence $\{\mathcal{K}_n = (K_n, K_n(1)) : n \in \mathbb{N}\}$ forms an orthogonal basis for $\mathcal{E}$ (cf.~\cref{prop:koorn_properties}), it follows then that the polynomial sequence \(\mcK_n^\tau := (K_n^\tau, K_n^\tau(0)) : n \in \mathbb{N}\}\) forms an orthogonal basis for the space $\mathcal{H} = L^2([-\tau,0); \mathbb{R}) \times  \mathbb{R}$ endowed with the inner product $\langle \cdot, \cdot \rangle_{\mathcal{H}}$ defined in \cref{H_inner}. We define \(S_N^\tau\) similarly. It can be verified that \cref{lemma:S_N} and \cref{prop:uniform-conv} are preserved in \(\mcH\).

We are now able to define
\be
    \mcH_N := \mathrm{span}\{\mcK_0^\tau, \ldots, \mcK_N^\tau \}.
\ee
Let \(\Pi_N\) be the associated orthogonal projector of \(\mcH_N\). By the construction of the orthogonal basis \(\{\mcK^\tau_n\}\), we have that \(\mcH_N\subset D(\mcA).\) The \(N\)-dimensional Galerkin approximation of \cref{eq:abstract_ode} is 
\bea\label{eq:abstract_gal_ode}
    \frac{\d u_N}{\d t} &= \mcA_N u_N + \Pi_N \mcF(u_N), \\
    u_N(0) &= \Pi_N u_0,
\eea
where \(\mcA_N := \Pi_N\mcA \Pi_N\). The linear operator \(\mcA_N\) on the finite dimensional space \(\mcH_N\) defines the \(C_0\)-semigroup \(e^{\mcA_N t}\). This can be extended to a \(C_0\)-semigroup on \(\mcH\):
\be
    T_N(t) u=e^{\mathcal{A}_N t} \Pi_N u +(I-\Pi_N) u, \; u\in \mathcal{H}.
\ee
From \cref{eq:abstract_gal_ode}, we derive the variation of constants formula for the Galerkin approximation:
\be
    u_N(t) = T_N(t)\Pi_N u_0 + \int_0^t T_N(t-s)\Pi_N\mcF(u_N(t))\d s.
\ee
By \cite[Lemma~4.3]{CGLW16} and the proof of \cite[Thm.~4.1]{CGLW16}, the results about \(T(t)\) and \(T_N(t)\) hold.

\bprop
For \(t>0\) and \(N\in\mathbb N_0\),
\be
    \| T_N(t) \|_\mcH , \| T(t) \|_\mcH \leq Me^{\omega t}.
\ee
Also, for any \(T>0\),
\be\label{eq:trotter_kato}
    \lim_{N\to\infty}\sup_{t\in[0,T]} \| T(t)u - T_N(t)\Pi_Nu \|_\mcH = 0, \quad \forall u\in\mcH.
\ee
\eprop
The proof of \cref{eq:trotter_kato} relies on a version of the Trotter-Kato theorem \cite[Thm.~4.5, p.~88]{P83}.


\subsection{Vectorized Koornwinder Polynomials}\label{section:vectorized-koornwinder}
We now wish to vectorize the polynomials from the previous subsection so that they form an orthogonal basis for 
\be
    \mcH^{\boldtau} :=  L^2([-\tau_1,0);\mathbb R) \times \cdots \times L^2([-\tau_p, 0); \mathbb R) \times \mathbb R^p,
\ee
where \(\boldtau = (\tau_1, \tau_2,\cdots, \tau_p)\) with \(0<\tau_1\leq\tau_2\leq\cdots\leq\tau_p\). The inner product of this space is given by
\be
    \ip{\Psi}{\Phi}_{\mcH^{\boldtau}} = \sum_{i=1}^p \frac 1 {\tau_i}\int_{-\tau_i}^0 \Psi^D_i(\theta)\Phi^D_i(\theta) \d\theta + \ip{\Psi^S}{\Phi^S}, \qquad \forall\Psi,\Phi\in\mcH^{\boldtau}.
\ee
The construction will be similar to that in \cite[Section~3.3]{CGLW16}. For \(j\in\mathbb N\), let 
\be 
    d_j = \left\lfloor \frac{j-1} p\right\rfloor
\ee 
and let \[r_j = \begin{cases} \mbox{mod}(j, p), & \mbox{ if } \mod(j,p) \neq 0 \\ p, & \mbox{otherwise} \end{cases}.\] Define 
\be
    \mathbf{K}_j^{\boldtau} := (\underbrace{0,\ldots,0,}_\text{$r_j$ - 1 entries} K_{d_j}^{\tau_{r_j}},  \underbrace{0, \ldots, 0}_\text{$p-r_j$ entries}). 
\ee
We shall also define
\be
    \mathbf{K}_j^{\boldtau}(0) := (\underbrace{0,\ldots,0,}_\text{\(r_j\) - 1 entries} K_{d_j}^{\tau_{r_j}}(0),  \underbrace{0, \ldots, 0}_\text{\(p-r_j\) entries}). 
\ee
We introduce 
\be
    \mathbb K_j^{\boldtau} := (\mathbf K_j^{\boldtau}, \mathbf K_j^{\boldtau}(0)),\qquad j\in\mathbb N.
\ee
One can check that \(\{\mathbb K_j^{\boldtau}: j\in\mathbb N\}\) forms an orthogonal basis for \(\mcH^{\boldtau}\). We define 
\be
    \mathcal X := L^2([-\tau_1,0);\mathbb R) \times \cdots \times L^2([-\tau_p,0);\mathbb R)
\ee 
and 
\be
    \langle f, g\rangle_{\mathcal X} = \sum_{i=1}^p \frac 1 {\tau_i} \int_{-\tau_i}^0 f(\theta)g(\theta)\d\theta,
\ee
i.e., \(\mathcal X\) is the delay part of \(\mcH^{\boldtau}\). 
\bprop
The following convergence results hold for any \(f\in\mathcal X\) and \(\alpha\in\mathbb R^p\):
\bea
    &\sum_{j=1}^\infty \frac{\langle\alpha, \mathbf{K}_j^{\boldtau}(0)\rangle}{\|\mathbb K _j^{\boldtau}\|_{\mathcal H}}\mathbf K_j^{\boldtau} = 0 \quad \mbox{ with respect to $\|\cdot\|_{\mathcal X}$;} \\
    &\sum_{j=1}^\infty \frac{\langle\alpha, \mathbf{K}_j^{\boldtau}(0)\rangle}{\|\mathbb K _j^{\boldtau}\|_{\mathcal H}}\mathbf K_j^{\boldtau}(0) = \alpha; \\
    &\sum_{j=1}^\infty \frac{\langle\alpha, \mathbf{K}_j^{\boldtau}\rangle_{\mathcal X}}{\|\mathbb K _j^{\boldtau}\|_{\mathcal H}}\mathbf K_j^{\boldtau} = f \quad \mbox{ with respect to $\|\cdot\|_{\mathcal X}$; and }  \\
    &\sum_{j=1}^\infty \frac{\langle\alpha, \mathbf{K}_j^{\boldtau}\rangle_{\mathcal X}}{\|\mathbb K _j^{\boldtau}\|_{\mathcal H}}\mathbf K_j^{\boldtau}(0) = 0. \\
\eea
\eprop

\bp
Note that \(\{\mathbb K_j^{\boldtau}: j\in\mathbb N\}\) forms an orthogonal basis for \(\mathcal H\). Then for \(\Psi =(\Psi^D, \Psi^S) \in\mathcal H\), we have the following decomposition
\bea\label{eq:p-side-comparison}
    \Psi &= \sum_{j=1}^\infty \frac{\iph \Psi {\mathbb K_j^{\boldtau}}}{\|\mathbb K_j^{\boldtau}\|^2_{\mathcal H}}\mathbb K_j^{\boldtau} \\
    &= \sum_{j=1}^\infty \left(\ipx {\Psi^D} {\mathbf K_j^{\boldtau}} + \ip {\Psi^S}{\mathbf K^{\boldtau}_j(0)}\right)\frac{\mathbb K_j^{\boldtau}}{\|\mathbb K_j^{\boldtau}\|^2_{\mathcal H}}.
\eea
If we set \(\Psi = (\mathbf 0, \alpha) \in\mathcal H_p\) and equalize the functional and numerical parts of each side of \cref{eq:p-side-comparison}, we get the first two convergence results. Similarly, setting \(\Psi = (f, \mathbf 0)\) and equalizing the functional and numerical parts of \cref{eq:p-side-comparison}, we get the last two convergence results.
\ep

For the case when \(\boldtau = (\tau, \tau, \cdots, \tau)\) for \(\tau> 0\), we may write \(\mathbb K^\tau_n\) instead of \(\mathbb K^{\boldtau}_n\). In this case, our construction corresponds exactly to the \(\mathbb K^\tau_n\) described in \cite[Section~3.3]{CGLW16}